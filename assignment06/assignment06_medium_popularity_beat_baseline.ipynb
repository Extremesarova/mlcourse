{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://habrastorage.org/webt/ia/m9/zk/iam9zkyzqebnf_okxipihkgjwnw.jpeg\" />\n",
    "    \n",
    "**<center>[mlcourse.ai](https://mlcourse.ai) – Open Machine Learning Course** </center><br>\n",
    "Author: [Yury Kashnitskiy](https://yorko.github.io) (@yorko). [mlcourse.ai](https://mlcourse.ai) is powered by [OpenDataScience (ods.ai)](https://ods.ai/) © 2017—2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Assignment #6. Task</center><a class=\"tocSkip\">\n",
    "### <center> Beating benchmarks in \"How good is your Medium article?\"</center><a class=\"tocSkip\">\n",
    "    \n",
    "[Competition](https://www.kaggle.com/c/how-good-is-your-medium-article). The task is to beat \"Assignment 6 baseline\" (~1.45 Public LB score). You can refer to [this simple Ridge baseline](https://www.kaggle.com/kashnitsky/ridge-countvectorizer-baseline?rvi=1).\n",
    "\n",
    "*For discussions, please stick to [ODS Slack](https://opendatascience.slack.com/), channel __#mlcourse_ai_eng__, pinned thread __#a6_bonus__. If you are sure that something is not 100% correct, please leave your feedback there*\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xgboost nltk dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from html.parser import HTMLParser\n",
    "from pathlib import Path\n",
    "\n",
    "import dill as pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from nltk import TweetTokenizer\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS, TfidfVectorizer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "PATH_TO_DATA = \"data\"\n",
    "PATH_TO_SAVE_DIR = \"prepared_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will help to throw away all HTML tags from an article content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from html.parser import HTMLParser\n",
    "\n",
    "\n",
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs = True\n",
    "        self.fed = []\n",
    "\n",
    "    def handle_data(self, d):\n",
    "        self.fed.append(d)\n",
    "\n",
    "    def get_data(self):\n",
    "        return \"\".join(self.fed)\n",
    "\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supplementary function to read a JSON line without crashing on escape characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_line(line=None):\n",
    "    result = None\n",
    "    try:\n",
    "        result = json.loads(line)\n",
    "    except Exception as e:\n",
    "        # Find the offending character index:\n",
    "        idx_to_replace = int(str(e).split(\" \")[-1].replace(\")\", \"\"))\n",
    "        # Remove the offending character:\n",
    "        new_line = list(line)\n",
    "        new_line[idx_to_replace] = \" \"\n",
    "        new_line = \"\".join(new_line)\n",
    "        return read_json_line(line=new_line)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract features `content`, `published`, `title` and `author`, write them to separate files for train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_file(filename):\n",
    "    file = Path(filename)\n",
    "    return file.is_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_disk(features, path_to_save, prefix):\n",
    "    reload_files = False\n",
    "    d = defaultdict()\n",
    "    for feature in features:\n",
    "        filename = os.path.join(path_to_save, prefix + \"_\" + feature + \".txt\")\n",
    "        if check_file(filename):\n",
    "            print(f\"Reading from disk {filename}\")\n",
    "            with open(filename, \"rb\") as fp:\n",
    "                d[feature] = pickle.load(fp)\n",
    "        else:\n",
    "            reload_files = True\n",
    "\n",
    "    return reload_files, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_and_write(path_to_data, path_to_save, inp_filename, is_train=True):\n",
    "    titles = []\n",
    "    contents = []\n",
    "    dates = []\n",
    "\n",
    "    authors = []\n",
    "    features = [\"content\", \"published\", \"title\", \"author\"]\n",
    "    prefix = \"train\" if is_train else \"test\"\n",
    "\n",
    "    Path(path_to_save).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    reload_files, d = read_from_disk(features, path_to_save, prefix)\n",
    "\n",
    "    if reload_files:\n",
    "\n",
    "        feature_files = [\n",
    "            open(os.path.join(path_to_save, \"{}_{}.txt\".format(prefix, feat)), \"w\", encoding=\"utf-8\")\n",
    "            for feat in features\n",
    "        ]\n",
    "\n",
    "        with open(os.path.join(path_to_data, inp_filename), encoding=\"utf-8\") as inp_json_file:\n",
    "\n",
    "            for line in tqdm(inp_json_file, desc=f\"Reading {prefix} json files\"):\n",
    "                json_data = read_json_line(line)\n",
    "\n",
    "                title = json_data[\"title\"].replace(\"\\n\", \" \").replace(\"\\t\", \" \").replace(\"\\r\", \" \").replace(\"\\xa0\", \" \")\n",
    "                content = strip_tags(\n",
    "                    json_data[\"content\"].replace(\"\\n\", \" \").replace(\"\\t\", \" \").replace(\"\\r\", \" \").replace(\"\\xa0\", \" \")\n",
    "                )\n",
    "                published = json_data[\"published\"]\n",
    "                author = json_data[\"meta_tags\"][\"author\"]\n",
    "                authors_name = json_data[\"meta_tags\"][\"author\"]\n",
    "\n",
    "                titles.append(title)\n",
    "                contents.append(content)\n",
    "                dates.append(published)\n",
    "                authors.append(authors_name)\n",
    "\n",
    "        d = {\"content\": contents, \"published\": dates, \"title\": titles, \"author\": authors}\n",
    "        for feature in features:\n",
    "            filename = prefix + \"_\" + feature + \".txt\"\n",
    "            with open(os.path.join(path_to_save, filename), \"wb\") as fp:\n",
    "                pickle.dump(d[feature], fp)\n",
    "    else:\n",
    "        titles, contents, dates, authors = d[\"title\"], d[\"content\"], d[\"published\"], d[\"author\"]\n",
    "\n",
    "    return titles, contents, dates, authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the [competition data](https://www.kaggle.com/c/how-good-is-your-medium-article/data) and place it where it's convenient for you. You can modify the path to data below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from disk prepared_data\\train_content.txt\n",
      "Reading from disk prepared_data\\train_published.txt\n",
      "Reading from disk prepared_data\\train_title.txt\n",
      "Reading from disk prepared_data\\train_author.txt\n",
      "Reading from disk prepared_data\\test_content.txt\n",
      "Reading from disk prepared_data\\test_published.txt\n",
      "Reading from disk prepared_data\\test_title.txt\n",
      "Reading from disk prepared_data\\test_author.txt\n"
     ]
    }
   ],
   "source": [
    "train_titles, train_contents, train_dates, train_authors = extract_features_and_write(\n",
    "    PATH_TO_DATA, PATH_TO_SAVE_DIR, \"train.json\", is_train=True\n",
    ")\n",
    "test_titles, test_contents, test_dates, test_authors = extract_features_and_write(\n",
    "    PATH_TO_DATA, PATH_TO_SAVE_DIR, \"test.json\", is_train=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add the following groups of features:**\n",
    "* Tf-Idf with article content:\n",
    "  * ngram_range=(1, 2)\n",
    "  * max_features=100000\n",
    "* Tf-Idf with article titles:\n",
    "  * ngram_range=(1, 2)\n",
    "  * max_features=100000\n",
    "* Time features: \n",
    "  * publication hour, \n",
    "  * time of the day \n",
    "  * weekend or not\n",
    "* Bag of authors  \n",
    "i.e. One-Hot-Encoded author names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TITLE_NGRAMS = (1, 2)  # for tf-idf on titles\n",
    "CONTENT_NGRAMS = (1, 2)  # for tf-idf on contents\n",
    "MAX_FEATURES = 100_000  # for tf-idf\n",
    "\n",
    "XGB_TRAIN_ROUNDS = 60  # num. iteration to train XGBoost\n",
    "XGB_NUM_LEAVES = 255  # max number of leaves in XGBoost trees\n",
    "XGB_WEIGHT = 0.4\n",
    "\n",
    "MEAN_TEST_TARGET = 4.33328  # what we got by submitting all zeros\n",
    "\n",
    "RIDGE_WEIGHT = 0.6  # weight of Ridge predictions in a blend with XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TweetTokenizer()\n",
    "assert tokenizer.tokenize(\"Now I'm a man\") == [\"Now\", \"I'm\", \"a\", \"man\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing TF-IDF vectorization for articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_vec_params = {\n",
    "    \"ngram_range\": CONTENT_NGRAMS,\n",
    "    \"max_features\": MAX_FEATURES,\n",
    "    \"tokenizer\": tokenize,\n",
    "    \"stop_words\": ENGLISH_STOP_WORDS,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'art_vec_params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m article_vectorizer_params_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mart_vec_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mngram_range\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mart_vec_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m article_vec_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvectorizer_article_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marticle_vectorizer_params_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'art_vec_params' is not defined"
     ]
    }
   ],
   "source": [
    "article_vectorizer_params_str = f\"{art_vec_params['ngram_range']}_{art_vec_params['max_features']}\"\n",
    "article_vec_name = f\"vectorizer_article_{article_vectorizer_params_str}.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "article_vec_is_saved = check_file(article_vec_name)\n",
    "if article_vec_is_saved:\n",
    "    vectorizer_article = pickle.load(open(article_vec_name, \"rb\"))\n",
    "else:\n",
    "    vectorizer_article = TfidfVectorizer(**article_vectorizer_params)\n",
    "    vectorizer_article.fit(train_contents)\n",
    "    pickle.dump(vectorizer_article, open(article_vec_name, \"wb\"))\n",
    "    \n",
    "X_train_article = vectorizer_article.transform(train_contents)\n",
    "X_test_article = vectorizer_article.transform(test_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing TF-IDF vectorization for titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_vec_params = {\n",
    "    \"ngram_range\": TITLE_NGRAMS,\n",
    "    \"max_features\": MAX_FEATURES,\n",
    "    \"tokenizer\": tokenize,\n",
    "    \"stop_words\": ENGLISH_STOP_WORDS,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_vectorizer_params_str = f\"{title_vec_params['ngram_range']}_{title_vec_params['max_features']}\"\n",
    "title_vec_name = f\"vectorizer_title_{title_vectorizer_params_str}.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 6.14 s\n",
      "Wall time: 6.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "title_vec_is_saved = check_file(title_vec_name)\n",
    "if title_vec_is_saved:\n",
    "    vectorizer_title = pickle.load(open(title_vec_name, \"rb\"))\n",
    "else:\n",
    "    vectorizer_title = TfidfVectorizer(**title_vec_params)\n",
    "    vectorizer_title.fit(train_titles)\n",
    "    pickle.dump(vectorizer_title, open(title_vec_name, \"wb\"))\n",
    "\n",
    "X_train_title = vectorizer_title.transform(train_titles)\n",
    "X_test_title = vectorizer_title.transform(test_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preparing time features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time features\n",
    "def add_time_features(dates):\n",
    "    scaler = StandardScaler()\n",
    "    hour = scaler.fit_transform(np.array([date.hour for date in dates]).reshape(-1, 1))\n",
    "    weekday = scaler.fit_transform(np.array([date.weekday() for date in dates]).reshape(-1, 1))\n",
    "    morning = scaler.fit_transform(((hour >= 7) & (hour <= 11)).astype(\"int\").reshape(-1, 1))\n",
    "    day = scaler.fit_transform(((hour >= 12) & (hour <= 18)).astype(\"int\").reshape(-1, 1))\n",
    "    evening = scaler.fit_transform(((hour >= 19) & (hour <= 23)).astype(\"int\").reshape(-1, 1))\n",
    "    night = scaler.fit_transform(((hour >= 0) & (hour <= 6)).astype(\"int\").reshape(-1, 1))\n",
    "    weekend_temp = np.array([date.weekday() for date in dates]).reshape(-1, 1)\n",
    "    weekend = scaler.fit_transform(((weekend_temp >= 5) & (weekend_temp <= 6)).astype(\"int\").reshape(-1, 1))\n",
    "\n",
    "    feature_names = [\"morning\", \"day\", \"evening\", \"night\", \"weekday\"]\n",
    "    time_features = pd.DataFrame(\n",
    "        list(zip(morning.flatten(), day.flatten(), evening.flatten(), night.flatten(), weekend.flatten())),\n",
    "        columns=feature_names,\n",
    "    )\n",
    "    sparse_time_features = csr_matrix(time_features.values)\n",
    "    return sparse_time_features, feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_times = pd.to_datetime([date[\"$date\"] for date in train_dates])\n",
    "test_times = pd.to_datetime([date[\"$date\"] for date in test_dates])\n",
    "\n",
    "X_train_time_features_sparse, time_feature_names = add_time_features(train_times)\n",
    "X_test_time_features_sparse, _ = add_time_features(test_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing bag of authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = np.unique(train_authors + test_authors)\n",
    "enc = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "enc.fit(authors.reshape(-1, 1))\n",
    "enc.categories_\n",
    "X_train_author_sparse = enc.transform(np.array(train_authors).reshape(-1, 1)).toarray()\n",
    "X_test_author_sparse = enc.transform(np.array(test_authors).reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = [len(article) for article in train_contents]\n",
    "test_len = [len(article) for article in test_contents]\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_len_sparse = scaler.fit_transform(np.array(train_len).reshape(-1, 1))\n",
    "X_test_len_sparse = scaler.fit_transform(np.array(test_len).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Join all sparse matrices.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sparse = hstack(\n",
    "    [X_train_article, X_train_title, X_train_author_sparse, X_train_time_features_sparse, X_train_len_sparse]\n",
    ").tocsr()\n",
    "\n",
    "X_test_sparse = hstack(\n",
    "    [X_test_article, X_test_title, X_test_author_sparse, X_test_time_features_sparse, X_test_len_sparse]\n",
    ").tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read train target and split data for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = pd.read_csv(os.path.join(PATH_TO_DATA, \"train_log1p_recommends.csv\"), index_col=\"id\")\n",
    "y_train = train_target[\"log_recommends\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_part_size = int(0.7 * train_target.shape[0])\n",
    "\n",
    "X_train_part_sparse = X_train_sparse[:train_part_size, :]\n",
    "y_train_part = y_train[:train_part_size]\n",
    "\n",
    "X_valid_sparse = X_train_sparse[train_part_size:, :]\n",
    "y_valid = y_train[train_part_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train a simple Ridge model and check MAE on the validation set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha_values = np.logspace(-2, 2, 20)\n",
    "ridge = Ridge(random_state=SEED, alpha=0.01)\n",
    "# logit_grid_searcher = GridSearchCV(estimator=ridge, param_grid={'alpha': alpha_values}, scoring='neg_mean_absolute_error', n_jobs=-1, cv=3, verbose=1)\n",
    "ridge.fit(X_train_sparse, y_train)\n",
    "# final_model = logit_grid_searcher.best_estimator_\n",
    "ridge_test_pred = ridge.predict(X_test_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_x_train = lgb.Dataset(X_train_sparse.astype(np.float32), label=np.log1p(y_train))\n",
    "param = {\"num_leaves\": LGB_NUM_LEAVES, \"objective\": \"mean_absolute_error\", \"metric\": \"mae\"}\n",
    "bst_lgb = lgb.train(param, lgb_x_train, LGB_TRAIN_ROUNDS, verbose_eval=5)\n",
    "lgb_test_pred = np.expm1(bst_lgb.predict(X_test_sparse.astype(np.float32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with all data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the same Ridge with all available data, make predictions for the test set and form a submission file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You code here (read-only in a JupyterBook, pls run jupyter-notebook to edit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_test_pred = np.empty([34645, 1])  # change this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_submission_file(\n",
    "    prediction,\n",
    "    filename,\n",
    "    path_to_sample=os.path.join(PATH_TO_DATA, \"sample_submission.csv\"),\n",
    "):\n",
    "    submission = pd.read_csv(path_to_sample, index_col=\"id\")\n",
    "\n",
    "    submission[\"log_recommends\"] = prediction\n",
    "    submission.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission_file(ridge_test_pred, os.path.join(PATH_TO_DATA, \"assignment6_medium_submission.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now's the time for dirty Kaggle hacks. Form a submission file with all zeros. Make a submission. What do you get if you think about it? How is it going to help you with modifying your predictions?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission_file(\n",
    "    np.zeros_like(ridge_test_pred),\n",
    "    os.path.join(PATH_TO_DATA, \"medium_all_zeros_submission.csv\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modify predictions in an appropriate way (based on your all-zero submission) and make a new submission.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_test_pred_modif = ridge_test_pred\n",
    "# You code here (read-only in a JupyterBook, pls run jupyter-notebook to edit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission_file(\n",
    "    ridge_test_pred_modif,\n",
    "    os.path.join(PATH_TO_DATA, \"assignment6_medium_submission_with_hack.csv\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it for the assignment. In case you'd like to try some more ideas for improvement:\n",
    "\n",
    "- Engineer good features, this is the key to success. Some simple features will be based on publication time, authors, content length and so on\n",
    "- You may not ignore HTML and extract some features from there\n",
    "- You'd better experiment with your validation scheme. You should see a correlation between your local improvements and LB score\n",
    "- Try TF-IDF, ngrams, Word2Vec and GloVe embeddings\n",
    "- Try various NLP techniques like stemming and lemmatization\n",
    "- Tune hyperparameters. In our example, we've left only 50k features and used C=1 as a regularization parameter, this can be changed\n",
    "- SGD and Vowpal Wabbit will train much faster\n",
    "- Play around with blending and/or stacking. An intro is given in [this Kernel](https://www.kaggle.com/kashnitsky/ridge-and-lightgbm-simple-blending) by @yorko \n",
    "- And neural nets of course. We don't cover them in this course byt still transformer-based architectures will likely perform well in such types of tasks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlcourse_ai_bonus",
   "language": "python",
   "name": "mlcourse_ai_bonus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
